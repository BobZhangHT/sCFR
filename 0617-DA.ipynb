{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc5e68c",
   "metadata": {},
   "source": [
    "# Simulation Results Analyzer\n",
    "\n",
    "This notebook analyzes existing saved simulation results from the `run_simulation_notebook.ipynb` (or its script equivalent).\n",
    "\n",
    "**Functionality:**\n",
    "- Loads per-run metrics (`.json` files) from `OUTPUT_DIR_RUN_METRICS_JSON`.\n",
    "- Loads posterior summaries (mean, quantiles as `.npz` files) for the first MC run of each scenario from `OUTPUT_DIR_POSTERIOR_SUMMARIES`.\n",
    "- Regenerates true data (`sim_data`) for the first MC run of each scenario using stored seeds to provide context for plots.\n",
    "- Generates and saves individual time-series plots for the first MC run of each scenario (to `OUTPUT_DIR_PLOTS`).\n",
    "- Generates and saves a combined 4x3 grid plot of these time-series (to `OUTPUT_DIR_PLOTS`).\n",
    "- Generates and saves summary box plots for all evaluation metrics across all MC runs (to `OUTPUT_DIR_PLOTS`).\n",
    "- Aggregates metrics and produces LaTeX summary tables (to `OUTPUT_DIR_TABLES`).\n",
    "\n",
    "**Prerequisites:**\n",
    "1. The simulation runner notebook/script must have completed, and its output files must be available in the directories specified in `config.py`.\n",
    "2. All helper Python modules (`config.py`, `data_generation.py`, etc.) must be in the same directory or accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcecdf1",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ef1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configuration and output paths from config.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import your custom modules\n",
    "import config\n",
    "import data_generation\n",
    "import benchmarks\n",
    "import evaluation\n",
    "import plotting\n",
    "import tables\n",
    "import results_io\n",
    "\n",
    "print(\"Reading configuration and output paths from config.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f6cc8",
   "metadata": {},
   "source": [
    "## 2. Main Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff36c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_metrics_dataframe(df):\n",
    "    \"\"\"Cleans a DataFrame of metrics by converting list-like values to scalars.\"\"\"\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].notna().any() and isinstance(df[col].dropna().iloc[0], list):\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x\n",
    "                )\n",
    "    return df\n",
    "\n",
    "def prepare_aggregated_plot_data(results_df_all):\n",
    "    \"\"\"\n",
    "    Aggregates time-series results from all valid MC runs for the summary plot.\n",
    "    \"\"\"\n",
    "    aggregated_plot_data_list = []\n",
    "    study_global_seed = config.GLOBAL_BASE_SEED\n",
    "\n",
    "    for scenario_idx, scenario_config_dict in enumerate(tqdm(config.SCENARIOS, desc=\"Aggregating Plot Data\")):\n",
    "        scenario_id = scenario_config_dict[\"id\"]\n",
    "        scenario_base_seed = study_global_seed + (scenario_idx * config.NUM_MONTE_CARLO_RUNS * 1000)\n",
    "        \n",
    "        sim_data_true = data_generation.simulate_scenario_data(scenario_config_dict, run_seed=scenario_base_seed)\n",
    "        T_analyze = config.T_ANALYSIS_LENGTH\n",
    "\n",
    "        # Filter results for valid runs in this scenario\n",
    "        scen_df_valid = results_df_all[\n",
    "            (results_df_all[\"scenario_id\"] == scenario_id) & \n",
    "            (results_df_all[\"error\"].isin([None, \"None\"]))\n",
    "        ]\n",
    "        if scen_df_valid.empty: continue\n",
    "        \n",
    "        # Stacks for collecting time-series from all valid runs\n",
    "        sCFR_means, sCFR_lowers, sCFR_uppers, sCFR_cf_means, sCFR_cf_lowers, sCFR_cf_uppers = [], [], [], [], [], []\n",
    "        cCFR_means, cCFR_lowers, cCFR_uppers = [], [], []\n",
    "        aCFR_means, aCFR_lowers, aCFR_uppers = [], [], []\n",
    "\n",
    "        for mc_run_idx in scen_df_valid[\"mc_run\"].astype(int) - 1:\n",
    "            posterior_summary = results_io.load_posterior_summary_for_run(scenario_id, mc_run_idx, config.OUTPUT_DIR_POSTERIOR_SUMMARIES)\n",
    "            if posterior_summary:\n",
    "                # Append sCFR data\n",
    "                sCFR_means.append(posterior_summary.get(\"p_mean\", []))\n",
    "                sCFR_lowers.append(posterior_summary.get(\"p_q025\", []))\n",
    "                sCFR_uppers.append(posterior_summary.get(\"p_q975\", []))\n",
    "                sCFR_cf_means.append(posterior_summary.get(\"p_cf_mean\", []))\n",
    "                sCFR_cf_lowers.append(posterior_summary.get(\"p_cf_q025\", []))\n",
    "                sCFR_cf_uppers.append(posterior_summary.get(\"p_cf_q975\", []))\n",
    "\n",
    "            sim_data_run = data_generation.simulate_scenario_data(scenario_config_dict, run_seed=(scenario_base_seed + mc_run_idx))\n",
    "            benchmark_cis = benchmarks.calculate_benchmark_cis_with_bayesian(sim_data_run[\"d_t\"], sim_data_run[\"c_t\"], sim_data_run[\"f_s_true\"])\n",
    "            \n",
    "            # Append benchmark data\n",
    "            cCFR_means.append(benchmarks.calculate_crude_cfr(sim_data_run[\"d_t\"], sim_data_run[\"c_t\"], cumulative=True))\n",
    "            cCFR_lowers.append(benchmark_cis[\"cCFR_cumulative_lower\"])\n",
    "            cCFR_uppers.append(benchmark_cis[\"cCFR_cumulative_upper\"])\n",
    "            \n",
    "            aCFR_means.append(benchmarks.calculate_nishiura_cfr_cumulative(sim_data_run[\"d_t\"], sim_data_run[\"c_t\"], sim_data_run[\"f_s_true\"]))\n",
    "            aCFR_lowers.append(benchmark_cis[\"aCFR_cumulative_lower\"])\n",
    "            aCFR_uppers.append(benchmark_cis[\"aCFR_cumulative_upper\"])\n",
    "\n",
    "        # Calculate the point-wise average of the curves and intervals\n",
    "        agg_plot_dict = {\n",
    "            \"scenario_id\": scenario_id,\n",
    "            \"true_r_t\": sim_data_true[\"true_r_0_t\"][:T_analyze],\n",
    "            \"true_rcf_0_t\": sim_data_true[\"true_rcf_0_t\"][:T_analyze],\n",
    "            \"estimated_r_t_dict\": {\n",
    "                \"sCFR\": {\n",
    "                    \"mean\": np.mean([s for s in sCFR_means if len(s)>0], axis=0)[:T_analyze],\n",
    "                    \"lower\": np.mean([s for s in sCFR_lowers if len(s)>0], axis=0)[:T_analyze],\n",
    "                    \"upper\": np.mean([s for s in sCFR_uppers if len(s)>0], axis=0)[:T_analyze],\n",
    "                    \"cf_mean\": np.mean([s for s in sCFR_cf_means if len(s)>0], axis=0)[:T_analyze],\n",
    "                    \"cf_lower\": np.mean([s for s in sCFR_cf_lowers if len(s)>0], axis=0)[:T_analyze],\n",
    "                    \"cf_upper\": np.mean([s for s in sCFR_cf_uppers if len(s)>0], axis=0)[:T_analyze]\n",
    "                },\n",
    "                \"cCFR_cumulative\": {\n",
    "                    \"mean\": np.mean(cCFR_means, axis=0)[:T_analyze],\n",
    "                    \"lower\": np.mean(cCFR_lowers, axis=0)[:T_analyze],\n",
    "                    \"upper\": np.mean(cCFR_uppers, axis=0)[:T_analyze]\n",
    "                },\n",
    "                \"aCFR_cumulative\": {\n",
    "                    \"mean\": np.mean(aCFR_means, axis=0)[:T_analyze],\n",
    "                    \"lower\": np.mean(aCFR_lowers, axis=0)[:T_analyze],\n",
    "                    \"upper\": np.mean(aCFR_uppers, axis=0)[:T_analyze]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        aggregated_plot_data_list.append(agg_plot_dict)\n",
    "\n",
    "    return aggregated_plot_data_list\n",
    "\n",
    "def main_analysis():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the post-hoc analysis of simulation results.\n",
    "    \"\"\"\n",
    "    all_loaded_metrics_list = []\n",
    "    all_plot_data_for_first_runs = []\n",
    "    \n",
    "    print(\"Starting analysis of existing simulation results...\")\n",
    "    start_time_analysis = time.time()\n",
    "\n",
    "    for dir_path in [config.OUTPUT_DIR_PLOTS, config.OUTPUT_DIR_TABLES, config.OUTPUT_DIR_RESULTS_CSV]:\n",
    "        if not os.path.exists(dir_path): os.makedirs(dir_path)\n",
    "\n",
    "    study_global_seed = config.GLOBAL_BASE_SEED\n",
    "\n",
    "    for scenario_idx, scenario_config_dict in enumerate(tqdm(config.SCENARIOS, desc=\"Loading & Preparing Data\")):\n",
    "        scenario_id = scenario_config_dict[\"id\"]\n",
    "        scenario_base_seed = study_global_seed + (scenario_idx * config.NUM_MONTE_CARLO_RUNS * 1000)\n",
    "        \n",
    "        for mc_run_idx in range(config.NUM_MONTE_CARLO_RUNS):\n",
    "            run_metrics = results_io.load_run_metrics(scenario_id, mc_run_idx, config.OUTPUT_DIR_RUN_METRICS_JSON)\n",
    "            if run_metrics:\n",
    "                all_loaded_metrics_list.append(run_metrics)\n",
    "\n",
    "            # Prepare plot data for the first valid MC run of each scenario\n",
    "            if mc_run_idx == 0:\n",
    "                run_specific_seed_dgp = scenario_base_seed + mc_run_idx\n",
    "                sim_data = data_generation.simulate_scenario_data(scenario_config_dict, run_seed=run_specific_seed_dgp)\n",
    "                \n",
    "                posterior_summary = results_io.load_posterior_summary_for_run(\n",
    "                    scenario_id, mc_run_idx, config.OUTPUT_DIR_POSTERIOR_SUMMARIES\n",
    "                )\n",
    "                \n",
    "                if posterior_summary:\n",
    "                    T_analyze = config.T_ANALYSIS_LENGTH\n",
    "\n",
    "                    sCFR_est_plot = {\n",
    "                        \"mean\": posterior_summary.get(\"p_mean\", np.array([])),\n",
    "                        \"lower\": posterior_summary.get(\"p_q025\", np.array([])),\n",
    "                        \"upper\": posterior_summary.get(\"p_q975\", np.array([])),\n",
    "                        \"cf_mean\": posterior_summary.get(\"p_cf_mean\", np.array([])),\n",
    "                        \"cf_lower\": posterior_summary.get(\"p_cf_q025\", np.array([])),\n",
    "                        \"cf_upper\": posterior_summary.get(\"p_cf_q975\", np.array([]))\n",
    "                    }\n",
    "\n",
    "                    # r_t_mean_sCFR = posterior_summary.get(\"p_mean\", np.full(T_analyze, np.nan))\n",
    "                    # r_t_lower_sCFR = posterior_summary.get(\"p_q025\", np.full(T_analyze, np.nan))\n",
    "                    # r_t_upper_sCFR = posterior_summary.get(\"p_q975\", np.full(T_analyze, np.nan))\n",
    "                    # rcf_t_mean_sCFR = posterior_summary.get(\"p_cf_mean\", np.full(T_analyze, np.nan))\n",
    "\n",
    "                    # Calculate benchmark point estimates                    \n",
    "                    benchmark_r_t_estimates = {\n",
    "                        \"cCFR_cumulative\": benchmarks.calculate_crude_cfr(sim_data[\"d_t\"], sim_data[\"c_t\"], cumulative=True),\n",
    "                        \"aCFR_cumulative\": benchmarks.calculate_nishiura_cfr_cumulative(sim_data[\"d_t\"], sim_data[\"c_t\"], sim_data[\"f_s_true\"])\n",
    "                    }\n",
    "\n",
    "                    # Calculate benchmark credible intervals using the Bayesian Beta-Binomial method\n",
    "                    benchmark_cis = benchmarks.calculate_benchmark_cis_with_bayesian(\n",
    "                        sim_data[\"d_t\"], sim_data[\"c_t\"], sim_data[\"f_s_true\"]\n",
    "                    )\n",
    "\n",
    "                    plot_data_for_run = {\n",
    "                            \"scenario_id\": scenario_id, \"mc_run_idx\": mc_run_idx,\n",
    "                            \"true_r_t\": sim_data[\"true_r_0_t\"][:T_analyze], \n",
    "                            \"true_rcf_0_t\": sim_data[\"true_rcf_0_t\"][:T_analyze],\n",
    "                            \"estimated_r_t_dict\": {\n",
    "                                \"cCFR_cumulative\": {\n",
    "                                    \"mean\": benchmark_r_t_estimates[\"cCFR_cumulative\"][:T_analyze],\n",
    "                                    \"lower\": benchmark_cis[\"cCFR_cumulative_lower\"][:T_analyze],\n",
    "                                    \"upper\": benchmark_cis[\"cCFR_cumulative_upper\"][:T_analyze]\n",
    "                                },\n",
    "                                \"aCFR_cumulative\": {\n",
    "                                    \"mean\": benchmark_r_t_estimates[\"aCFR_cumulative\"][:T_analyze],\n",
    "                                    \"lower\": benchmark_cis[\"aCFR_cumulative_lower\"][:T_analyze],\n",
    "                                    \"upper\": benchmark_cis[\"aCFR_cumulative_upper\"][:T_analyze]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                    plot_data_for_run[\"estimated_r_t_dict\"][\"sCFR\"] = sCFR_est_plot\n",
    "                    all_plot_data_for_first_runs.append(plot_data_for_run)\n",
    "                else:\n",
    "                    print(f\"  Warning: Posterior summary not found for plotting Scen {scenario_id}, Run {mc_run_idx + 1}.\")\n",
    "    \n",
    "    if not all_loaded_metrics_list:\n",
    "        print(\"No metrics files found. Cannot generate plots or tables.\")\n",
    "        return\n",
    "        \n",
    "    # --- Aggregate results and generate outputs ---\n",
    "    results_df_all = pd.DataFrame(all_loaded_metrics_list)\n",
    "    results_df_all = sanitize_metrics_dataframe(results_df_all)\n",
    "    results_df_valid = results_df_all[results_df_all['error'].isin([None, \"None\"])].copy()\n",
    "    \n",
    "    if results_df_valid.empty:\n",
    "        print(\"No valid simulation runs found in the loaded metrics. Analysis cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    analysis_csv_path = os.path.join(config.OUTPUT_DIR_RESULTS_CSV, \"all_scenarios_metrics_aggregated_by_analyzer.csv\")\n",
    "    results_df_valid.to_csv(analysis_csv_path, index=False)\n",
    "    print(f\"\\nAggregated valid metrics saved to {analysis_csv_path}\")\n",
    "\n",
    "    # --- Generate Plots and Tables ---\n",
    "    print(\"\\nPreparing aggregated data for summary plot...\")\n",
    "    aggregated_plot_data = prepare_aggregated_plot_data(results_df_valid)\n",
    "    \n",
    "    print(\"Generating combined 4x3 aggregated summary plot...\")\n",
    "    plotting.plot_aggregated_scenarios_summary(aggregated_plot_data, config.OUTPUT_DIR_PLOTS)\n",
    "    \n",
    "    # This part should now work without KeyError because the upstream data is fixed.\n",
    "    print(\"Generating time-series plots from saved summaries...\")\n",
    "    for p_data in all_plot_data_for_first_runs:\n",
    "        plotting.plot_cfr_timeseries_from_data(p_data[\"scenario_id\"], p_data[\"mc_run_idx\"], p_data, config.OUTPUT_DIR_PLOTS)\n",
    "    \n",
    "    print(\"Generating combined 4x3 summary plot...\")\n",
    "    plotting.plot_all_scenarios_summary(all_plot_data_for_first_runs, config.OUTPUT_DIR_PLOTS)\n",
    "    \n",
    "    print(\"Generating summary boxplots from loaded metrics...\")\n",
    "    plotting.plot_metric_summary_boxplots(results_df_valid, config.OUTPUT_DIR_PLOTS)\n",
    "    \n",
    "    print(\"Generating LaTeX summary tables from loaded metrics...\")\n",
    "    # Find all columns that contain 'cover'\n",
    "    cover_cols = [col for col in results_df_valid.columns if 'cover' in col]\n",
    "    for col in cover_cols:\n",
    "        # Convert True/False to 1/0 so that .mean() calculates the coverage probability\n",
    "        results_df_valid[col] = results_df_valid[col].astype('Int64')\n",
    "    \n",
    "    summary_metrics_mean = results_df_valid.groupby(\"scenario_id\").mean(numeric_only=True).reset_index()\n",
    "    summary_metrics_std = results_df_valid.groupby(\"scenario_id\").std(numeric_only=True).reset_index()\n",
    "    \n",
    "    summary_metrics_mean = summary_metrics_mean.add_suffix('_mean').rename(columns={'scenario_id_mean':'scenario_id'})\n",
    "    summary_metrics_std = summary_metrics_std.add_suffix('_std').rename(columns={'scenario_id_std':'scenario_id'})\n",
    "    results_df_summary_for_tables = pd.merge(summary_metrics_mean, summary_metrics_std, on=\"scenario_id\", how=\"left\")\n",
    "    \n",
    "    tables.generate_rt_metrics_table(results_df_summary_for_tables, config.OUTPUT_DIR_TABLES)\n",
    "    tables.generate_param_metrics_table(results_df_summary_for_tables, config.OUTPUT_DIR_TABLES)\n",
    "\n",
    "    end_time_analysis = time.time()\n",
    "    print(f\"\\nAnalysis of existing results complete in {end_time_analysis - start_time_analysis:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d63a8",
   "metadata": {},
   "source": [
    "## 3. Execute Analysis\n",
    "\n",
    "Run the cell below to perform the analysis. Make sure the simulation output directories in `config.py` point to where your simulation results are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48d7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of existing simulation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading & Preparing Data: 100%|██████████████████████████████| 12/12 [00:00<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated valid metrics saved to ./simulation_outputs/results_csv/all_scenarios_metrics_aggregated_by_analyzer.csv\n",
      "\n",
      "Preparing aggregated data for summary plot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating Plot Data:   0%|                                          | 0/12 [00:00<?, ?it/s]/home/hengtao/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3859: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hengtao/miniconda3/lib/python3.12/site-packages/numpy/_core/_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Aggregating Plot Data:   0%|                                          | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mmain_analysis\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# --- Generate Plots and Tables ---\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPreparing aggregated data for summary plot...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m aggregated_plot_data = \u001b[43mprepare_aggregated_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating combined 4x3 aggregated summary plot...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m plotting.plot_aggregated_scenarios_summary(aggregated_plot_data, config.OUTPUT_DIR_PLOTS)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mprepare_aggregated_plot_data\u001b[39m\u001b[34m(results_df_all)\u001b[39m\n\u001b[32m     58\u001b[39m         aCFR_uppers.append(benchmark_cis[\u001b[33m\"\u001b[39m\u001b[33maCFR_cumulative_upper\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Calculate the point-wise average of the curves and intervals\u001b[39;00m\n\u001b[32m     61\u001b[39m     agg_plot_dict = {\n\u001b[32m     62\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscenario_id\u001b[39m\u001b[33m\"\u001b[39m: scenario_id,\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrue_r_t\u001b[39m\u001b[33m\"\u001b[39m: sim_data_true[\u001b[33m\"\u001b[39m\u001b[33mtrue_r_0_t\u001b[39m\u001b[33m\"\u001b[39m][:T_analyze],\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrue_rcf_0_t\u001b[39m\u001b[33m\"\u001b[39m: sim_data_true[\u001b[33m\"\u001b[39m\u001b[33mtrue_rcf_0_t\u001b[39m\u001b[33m\"\u001b[39m][:T_analyze],\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mestimated_r_t_dict\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     66\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msCFR\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     67\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m: np.mean([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sCFR_means \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s)>\u001b[32m0\u001b[39m], axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     68\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m\"\u001b[39m: np.mean([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sCFR_lowers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s)>\u001b[32m0\u001b[39m], axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     69\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m: np.mean([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sCFR_uppers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s)>\u001b[32m0\u001b[39m], axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcf_mean\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msCFR_cf_means\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m>\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mT_analyze\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m     71\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcf_lower\u001b[39m\u001b[33m\"\u001b[39m: np.mean([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sCFR_cf_lowers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s)>\u001b[32m0\u001b[39m], axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     72\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcf_upper\u001b[39m\u001b[33m\"\u001b[39m: np.mean([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sCFR_cf_uppers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s)>\u001b[32m0\u001b[39m], axis=\u001b[32m0\u001b[39m)[:T_analyze]\n\u001b[32m     73\u001b[39m             },\n\u001b[32m     74\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcCFR_cumulative\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     75\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m: np.mean(cCFR_means, axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     76\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m\"\u001b[39m: np.mean(cCFR_lowers, axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     77\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m: np.mean(cCFR_uppers, axis=\u001b[32m0\u001b[39m)[:T_analyze]\n\u001b[32m     78\u001b[39m             },\n\u001b[32m     79\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maCFR_cumulative\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     80\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m: np.mean(aCFR_means, axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     81\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m\"\u001b[39m: np.mean(aCFR_lowers, axis=\u001b[32m0\u001b[39m)[:T_analyze],\n\u001b[32m     82\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m: np.mean(aCFR_uppers, axis=\u001b[32m0\u001b[39m)[:T_analyze]\n\u001b[32m     83\u001b[39m             }\n\u001b[32m     84\u001b[39m         }\n\u001b[32m     85\u001b[39m     }\n\u001b[32m     86\u001b[39m     aggregated_plot_data_list.append(agg_plot_dict)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m aggregated_plot_data_list\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b294836-3edd-44a2-8fcf-bef88e2ca2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
